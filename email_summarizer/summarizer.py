# ìš”ì•½ ë° í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§ 

import re
from typing import List, Tuple, Dict
from collections import Counter
import math


def split_sentences(text: str) -> List[str]:
    """
    í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        text: ë¶„ë¦¬í•  í…ìŠ¤íŠ¸
        
    Returns:
        List[str]: ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
    """
    # ë¬¸ì¥ ë íŒ¨í„´ (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ)
    sentence_pattern = r'[.!?]+'
    
    # ë¬¸ì¥ ë¶„ë¦¬
    sentences = re.split(sentence_pattern, text)
    
    # ë¹ˆ ë¬¸ì¥ ì œê±° ë° ê³µë°± ì •ë¦¬
    sentences = [s.strip() for s in sentences if s.strip()]
    
    return sentences


def extract_words(text: str) -> List[str]:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        text: ë‹¨ì–´ë¥¼ ì¶”ì¶œí•  í…ìŠ¤íŠ¸
        
    Returns:
        List[str]: ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
    """
    # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ì¶”ì¶œ
    words = re.findall(r'[ê°€-í£a-zA-Z0-9]+', text.lower())
    
    # ë¶ˆìš©ì–´ ì œê±°
    stopwords = {
        'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë•Œ', 'ê³³', 'ë§', 'ì¼', 'ë…„', 'ì›”', 'ì¼',
        'ì‹œ', 'ë¶„', 'ì´ˆ', 'ê°œ', 'ëª…', 'ë²ˆ', 'íšŒ', 'ì°¨', 'ëŒ€', 'ë§ˆë¦¬', 'ê¶Œ', 'ì±„',
        'ê·¸ê²ƒ', 'ì´ê²ƒ', 'ì €ê²ƒ', 'ë¬´ì—‡', 'ì–´ë–¤', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–¸ì œ', 'ì–´ë””ì„œ',
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of',
        'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have',
        'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should',
        'ê·¸ë¦¬ê³ ', 'ë˜ëŠ”', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ê·¸ëŸ¬ë‚˜', 'ë”°ë¼ì„œ', 'ê·¸ë˜ì„œ', 'ê·¸ëŸ¬ë©´',
        'ì´ì œ', 'ì§€ê¸ˆ', 'ì˜¤ëŠ˜', 'ë‚´ì¼', 'ì–´ì œ', 'ì—¬ê¸°', 'ì €ê¸°', 'ê±°ê¸°', 'ì–´ë””'
    }
    
    # ë¶ˆìš©ì–´ ì œê±° ë° ê¸¸ì´ í•„í„°ë§
    words = [word for word in words if word not in stopwords and len(word) > 1]
    
    return words


def calculate_tf_idf_keywords(text: str, top_n: int = 10) -> List[Tuple[str, float]]:
    """
    TF-IDF ê¸°ë°˜ìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        text: í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  í…ìŠ¤íŠ¸
        top_n: ì¶”ì¶œí•  í‚¤ì›Œë“œ ê°œìˆ˜
        
    Returns:
        List[Tuple[str, float]]: (í‚¤ì›Œë“œ, TF-IDF ì ìˆ˜) ë¦¬ìŠ¤íŠ¸
    """
    # ë¬¸ì¥ ë¶„ë¦¬
    sentences = split_sentences(text)
    if not sentences:
        return []
    
    # ê° ë¬¸ì¥ì—ì„œ ë‹¨ì–´ ì¶”ì¶œ
    sentence_words = [extract_words(sentence) for sentence in sentences]
    
    # ì „ì²´ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
    all_words = extract_words(text)
    total_words = len(all_words)
    
    # ë‹¨ì–´ë³„ TF-IDF ì ìˆ˜ ê³„ì‚°
    word_scores = {}
    
    for word in set(all_words):
        # TF (Term Frequency) ê³„ì‚°
        tf = all_words.count(word) / total_words
        
        # IDF (Inverse Document Frequency) ê³„ì‚°
        sentences_with_word = sum(1 for words in sentence_words if word in words)
        idf = math.log(len(sentences) / (sentences_with_word + 1))
        
        # TF-IDF ì ìˆ˜
        tf_idf = tf * idf
        
        # ì¶”ê°€ ê°€ì¤‘ì¹˜ (íŠ¹ë³„í•œ íŒ¨í„´)
        bonus = 0.0
        if re.search(r'ì£¼ìš”|í•µì‹¬|ì¤‘ìš”|íŠ¹ì§•|ê¸°ëŠ¥|ëª©ì |ì˜ë¯¸|ê°œë°œ|ì‹œìŠ¤í…œ|í”„ë¡œì íŠ¸', word):
            bonus += 0.5
        if re.search(r'api|web|app|database|server|client|framework', word.lower()):
            bonus += 0.3
        
        word_scores[word] = tf_idf + bonus
    
    # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ Nê°œ ë°˜í™˜
    sorted_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)
    return sorted_words[:top_n]


def extract_keywords(text: str, top_n: int = 10) -> List[Tuple[str, int]]:
    """
    í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (ê¸°ì¡´ ë°©ì‹ - í˜¸í™˜ì„± ìœ ì§€)
    
    Args:
        text: í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  í…ìŠ¤íŠ¸
        top_n: ì¶”ì¶œí•  í‚¤ì›Œë“œ ê°œìˆ˜
        
    Returns:
        List[Tuple[str, int]]: (í‚¤ì›Œë“œ, ë¹ˆë„ìˆ˜) ë¦¬ìŠ¤íŠ¸
    """
    words = extract_words(text)
    word_counts = Counter(words)
    return word_counts.most_common(top_n)


def calculate_sentence_score(sentence: str, keywords: List[Tuple[str, float]]) -> float:
    """
    ë¬¸ì¥ì˜ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (ê°œì„ ëœ ë²„ì „)
    
    Args:
        sentence: ì ìˆ˜ë¥¼ ê³„ì‚°í•  ë¬¸ì¥
        keywords: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (TF-IDF ì ìˆ˜ í¬í•¨)
        
    Returns:
        float: ë¬¸ì¥ ì ìˆ˜
    """
    sentence_lower = sentence.lower()
    score = 0.0
    
    # í‚¤ì›Œë“œ í¬í•¨ ì ìˆ˜ (TF-IDF ì ìˆ˜ ë°˜ì˜)
    for keyword, tf_idf_score in keywords:
        if keyword in sentence_lower:
            score += tf_idf_score * 2  # TF-IDF ì ìˆ˜ì— ê°€ì¤‘ì¹˜
    
    # ë¬¸ì¥ ê¸¸ì´ ì ìˆ˜ (ìµœì  ê¸¸ì´ ë²”ìœ„)
    length = len(sentence)
    if 15 <= length <= 120:
        score += 1.5
    elif 10 <= length < 15 or 120 < length <= 200:
        score += 1.0
    elif length < 10:
        score += 0.3
    
    # íŠ¹ë³„í•œ íŒ¨í„´ ì ìˆ˜
    important_patterns = [
        (r'ì£¼ìš”|í•µì‹¬|ì¤‘ìš”|íŠ¹ì§•|ê¸°ëŠ¥|ëª©ì |ì˜ë¯¸', 3.0),
        (r'ì˜ˆì‹œ|ì˜ˆë¥¼|ì˜ˆì‹œë¡œ|êµ¬ì²´ì ìœ¼ë¡œ', 2.0),
        (r'ê°œë°œ|êµ¬í˜„|ì„¤ê³„|ì•„í‚¤í…ì²˜', 2.5),
        (r'ìµœì í™”|ì„±ëŠ¥|ë³´ì•ˆ|í…ŒìŠ¤íŠ¸', 2.0),
        (r'ê²°ë¡ |ìš”ì•½|ì •ë¦¬', 1.5)
    ]
    
    for pattern, pattern_score in important_patterns:
        if re.search(pattern, sentence):
            score += pattern_score
    
    # ìœ„ì¹˜ ì ìˆ˜ (ë¬¸ì¥ì˜ ìœ„ì¹˜ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜)
    sentences = split_sentences(sentence)
    if sentences:
        sentence_index = sentences.index(sentence) if sentence in sentences else 0
        total_sentences = len(sentences)
        
        # ì²« ë²ˆì§¸ ë¬¸ì¥ê³¼ ë§ˆì§€ë§‰ ë¬¸ì¥ì— ê°€ì¤‘ì¹˜
        if sentence_index == 0:
            score += 1.0
        elif sentence_index == total_sentences - 1:
            score += 0.8
        elif sentence_index < total_sentences * 0.3:  # ì•ë¶€ë¶„
            score += 0.5
    
    return score


def summarize_text(text: str, length: str = "short", language: str = "ko") -> Dict:
    """
    í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
    
    Args:
        text: ìš”ì•½í•  í…ìŠ¤íŠ¸
        length: ìš”ì•½ ê¸¸ì´ ("short" ë˜ëŠ” "long")
        language: ì–¸ì–´ ("ko" ë˜ëŠ” "en")
        
    Returns:
        Dict: ìš”ì•½ ê²°ê³¼
    """
    # ë¬¸ì¥ ë¶„ë¦¬
    sentences = split_sentences(text)
    
    if not sentences:
        return {
            "summary": "ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.",
            "keywords": [],
            "original_length": len(text),
            "summary_length": 0
        }
    
    # TF-IDF ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords_tfidf = calculate_tf_idf_keywords(text)
    
    # ë¬¸ì¥ ì ìˆ˜ ê³„ì‚°
    sentence_scores = []
    for sentence in sentences:
        score = calculate_sentence_score(sentence, keywords_tfidf)
        sentence_scores.append((sentence, score))
    
    # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    sentence_scores.sort(key=lambda x: x[1], reverse=True)
    
    # ìš”ì•½ ê¸¸ì´ ê²°ì •
    if length == "short":
        summary_count = min(3, len(sentences))
    else:  # long
        summary_count = min(5, len(sentences))
    
    # ìƒìœ„ ë¬¸ì¥ë“¤ ì„ íƒ
    selected_sentences = sentence_scores[:summary_count]
    
    # ì›ë˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    selected_sentences.sort(key=lambda x: sentences.index(x[0]))
    
    # ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
    summary_text = ". ".join([s[0] for s in selected_sentences]) + "."
    
    return {
        "summary": summary_text,
        "keywords": keywords_tfidf[:5],  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ
        "original_length": len(text),
        "summary_length": len(summary_text),
        "sentence_count": len(sentences),
        "selected_sentences": len(selected_sentences)
    }


def format_summary_output(summary_result: Dict, highlight: bool = False) -> str:
    """
    ìš”ì•½ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤. (ê°œì„ ëœ ë²„ì „)
    
    Args:
        summary_result: ìš”ì•½ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        highlight: í‚¤ì›Œë“œ ê°•ì¡° ì—¬ë¶€
        
    Returns:
        str: í¬ë§·íŒ…ëœ ìš”ì•½ ê²°ê³¼
    """
    output = []
    
    # ìš”ì•½ í…ìŠ¤íŠ¸
    output.append("ğŸ“ ìš”ì•½ ê²°ê³¼:")
    output.append("")
    
    if highlight and summary_result["keywords"]:
        # í‚¤ì›Œë“œ ê°•ì¡°ëœ ìš”ì•½ (ìƒ‰ìƒ ë° êµµê¸°)
        summary_text = summary_result["summary"]
        for keyword, score in summary_result["keywords"]:
            # ì¤‘ìš”ë„ì— ë”°ë¥¸ ê°•ì¡° ìŠ¤íƒ€ì¼
            if score > 1.0:
                summary_text = summary_text.replace(
                    keyword, f"\033[1;33m**{keyword}**\033[0m"  # ë…¸ë€ìƒ‰ êµµê²Œ
                )
            else:
                summary_text = summary_text.replace(
                    keyword, f"\033[1;36m**{keyword}**\033[0m"  # ì²­ë¡ìƒ‰ êµµê²Œ
                )
        output.append(summary_text)
    else:
        output.append(summary_result["summary"])
    
    output.append("")
    
    # í‚¤ì›Œë“œ (ì¤‘ìš”ë„ ìˆœ)
    if summary_result["keywords"]:
        output.append("ğŸ”‘ ì£¼ìš” í‚¤ì›Œë“œ (ì¤‘ìš”ë„ ìˆœ):")
        for i, (keyword, score) in enumerate(summary_result["keywords"], 1):
            if highlight:
                if score > 1.0:
                    output.append(f"  {i}. \033[1;33m**{keyword}**\033[0m (ì ìˆ˜: {score:.2f})")
                else:
                    output.append(f"  {i}. \033[1;36m**{keyword}**\033[0m (ì ìˆ˜: {score:.2f})")
            else:
                output.append(f"  {i}. {keyword} (ì ìˆ˜: {score:.2f})")
        output.append("")
    
    # í†µê³„ ì •ë³´
    output.append("ğŸ“Š ìš”ì•½ í†µê³„:")
    output.append(f"  â€¢ ì›ë³¸ ê¸¸ì´: {summary_result['original_length']:,}ì")
    output.append(f"  â€¢ ìš”ì•½ ê¸¸ì´: {summary_result['summary_length']:,}ì")
    output.append(f"  â€¢ ì••ì¶•ë¥ : {((1 - summary_result['summary_length'] / summary_result['original_length']) * 100):.1f}%")
    output.append(f"  â€¢ ë¬¸ì¥ ìˆ˜: {summary_result['sentence_count']}ê°œ â†’ {summary_result['selected_sentences']}ê°œ")
    
    return "\n".join(output) 